
# ğŸ–ï¸ Real-Time Hand Tracking & Sign Language Recognition

A real-time application for detecting hand gestures using Mediapipe and OpenCV, served through a WebSocket using FastAPI and visualized in a React frontend. This project is built for use cases such as sign language recognition and gesture-based interaction.

---

## ğŸ“¦ Features

- ğŸ–ï¸ Real-time hand detection using Mediapipe
- ğŸ“· Crops hand region from the live feed
- ğŸ§  Easily pluggable sign classification logic (via `sign_class`)
- ğŸ”Œ WebSocket-based communication for live video processing
- ğŸ“Š FPS and latency display for performance tracking
- ğŸŒ CORS-enabled to connect seamlessly with a React frontend

---

## ğŸ—ï¸ Project Structure

```
project/
â”‚
â”œâ”€â”€ main.py                        # FastAPI backend with WebSocket support
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ handTrack.py              # Hand detection and gesture utilities (Mediapipe)
â”‚   â””â”€â”€ sign_cls.py               # (Pluggable) Sign classification logic
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ VideoStream.jsx           # React component for capturing video and rendering result
â”‚
â””â”€â”€ README.md                     # Youâ€™re reading this ğŸ“˜
```

---
## ğŸ³ Docker Deployment

### ğŸ“¦ Build and Run

```bash
docker-compose up --build
Backend: http://localhost:8000
Frontend: http://localhost:3000
```

## ğŸš€ Getting Started

### 1ï¸âƒ£ Backend (FastAPI)

#### ğŸ”§ Requirements

```bash
pip install fastapi uvicorn opencv-python mediapipe numpy python-multipart
```

#### â–¶ï¸ Run the FastAPI server

```bash
uvicorn main:app --reload
```

By default, FastAPI runs at `http://127.0.0.1:8000`.

---

### 2ï¸âƒ£ Frontend (React)

> Assumes a React setup created with Vite or Create React App.

#### âš™ï¸ Install dependencies and run:

```bash
cd frontend
npm install
npm run dev
```

Make sure your frontend is served from `http://localhost:5173` (or change CORS in `main.py`).

---

## ğŸ” WebSocket Communication

- Frontend opens a WebSocket to `/ws/video`
- Sends base64-encoded video frames continuously
- Backend:
  - Detects hand and bounding box using Mediapipe
  - Sends back:
    - Annotated full frame
    - Cropped hand region
    - FPS and latency info

---

## âœ¨ Sample JSON Response

```json
{
  "processed": "data:image/jpeg;base64,...", // Annotated full frame
  "cropped": "data:image/jpeg;base64,..."    // Cropped hand image
}
```

---

## ğŸ“¸ Tech Stack

| Layer       | Tech           |
|-------------|----------------|
| Backend     | FastAPI, OpenCV, Mediapipe |
| Frontend    | React, WebSocket |
| Image Format| Base64 encoded JPEG |
| Deployment  | Localhost (dev) |

---

## ğŸ› ï¸ Future Enhancements

- âœŠ Integrate actual ASL classification using a trained model
- â˜ï¸ Deploy to cloud (e.g., Render, Vercel, or AWS)
- ğŸ® Add gesture-based controls or actions
- ğŸ§ª Add tests for backend frame processing

---

## ğŸ§‘â€ğŸ’» Author

Made with â¤ï¸ by Muhammad Afiq

